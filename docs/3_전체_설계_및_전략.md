# DeepSeek-OCR 전용 파이프라인 마스터 플랜
**작성일**: 2025-10-23
**목표**: DeepSeek-OCR의 `<|grounding|>` 능력만으로 스캔 PDF 전체 처리

---

## 🧠 핵심 전략 (Deep Thinking)

### 1. DeepSeek-OCR의 능력 재정의

**확인된 능력**:
- ✅ **Bounding Box 검출** (`<|grounding|>` 모드)
- ✅ **레이아웃 인식** (SAM-base + CLIP-large)
- ✅ **요소 분류** (텍스트/표/그래프/다이어그램)
- ✅ **구조화된 데이터 추출** (Markdown 테이블, JSON)
- ✅ **맥락 이해** (주변 텍스트 연결)
- ✅ **OCR** (텍스트 레이어 없는 스캔 문서)

**제한사항**:
- ❌ 한 번에 전체 페이지의 모든 요소를 bbox까지 정확히 추출하는 것은 불확실
- ⚠️ 복잡한 레이아웃에서 bbox 정확도 검증 필요
- ⚠️ 한국어 처리 성능 검증 필요

### 2. 문서 구조 분석

**SUT 기술 문서 특성** (TP-030-030-030.pdf 기준):
```
[고정 헤더]
- 부서명, 문서번호, Rev., 작성일, 페이지 등

[본문 구조]
- 넘버링 제목 (1., 1.1., 1.1.1.)
- 텍스트 단락
- 표 (정형/비정형)
- 그래프 (막대/선/파이)
- 다이어그램 (공정도/순서도)
- 복합 이미지 (MES 화면 캡처 등)

[고정 푸터]
- 승인자, 검토자 정보
```

### 3. 2단계 추출 전략

**문제**: DeepSeek-OCR이 한 번에 모든 요소를 정확히 추출할 수 있는지 불확실

**해결책**: **2-Pass 전략**

**Pass 1: 전체 페이지 구조 분석** (페이지당 1회)
```python
prompt = """<image>
<|grounding|>Analyze this Korean steel mill technical document page:

1. Detect ALL visual elements with bounding boxes:
   - Text blocks (headers, sections, paragraphs with numbering)
   - Tables
   - Graphs/Charts
   - Diagrams (flowcharts, process diagrams)
   - Complex images (MES screens, composite layouts)

2. Extract document structure:
   - Page header (department, doc number, revision, date, page number)
   - Numbered sections (1., 1.1., 1.1.1., etc.)
   - Page footer (approvers, reviewers)

3. Return as structured JSON:
{
  "header": {"department": "...", "doc_number": "...", ...},
  "elements": [
    {
      "id": "elem_1",
      "type": "text_section",  // text_header|text_section|text_paragraph|table|graph|diagram|complex_image
      "bbox": {"x": 100, "y": 200, "width": 800, "height": 150, "page": 1},
      "numbering": "1.2.3",  // if applicable
      "preview": "첫 50자 텍스트..."
    },
    ...
  ],
  "footer": {"approver": "...", "reviewer": "..."}
}
"""
```

**Pass 2: 요소별 상세 분석** (요소당 1회)
```python
# 각 요소를 crop하여 개별 분석
for element in elements:
    cropped_image = crop_bbox(page_image, element['bbox'])

    if element['type'] == 'table':
        prompt = table_analysis_prompt(element, context)
    elif element['type'] == 'graph':
        prompt = graph_analysis_prompt(element, context)
    elif element['type'] == 'diagram':
        prompt = diagram_analysis_prompt(element, context)
    # ...

    analysis = deepseek_ocr.analyze(cropped_image, prompt)
```

**장점**:
- ✅ 1차 Pass: 빠른 전체 구조 파악
- ✅ 2차 Pass: 요소별 정밀 분석 (맥락 정보 포함)
- ✅ Bbox 재사용: 요소 crop, 저장, 검색에 활용

---

## 📋 전체 파이프라인 설계

### Phase 1: PDF → 페이지 이미지

```python
class PDFParser:
    def parse(pdf_path) -> List[PageImage]:
        # PyMuPDF + pdf2image
        # DPI: 200 (속도와 품질 균형)
        return page_images
```

### Phase 2: 전체 페이지 구조 분석 (Pass 1)

```python
class PageStructureAnalyzer:
    """DeepSeek-OCR <|grounding|> 모드로 전체 페이지 구조 추출"""

    def analyze_page_structure(page_image) -> PageStructure:
        prompt = STRUCTURE_ANALYSIS_PROMPT
        result = deepseek_ocr.infer(prompt, page_image)

        return PageStructure(
            header=DocumentHeader(...),
            elements=List[ElementDetection],  # type, bbox, preview
            footer=DocumentFooter(...)
        )
```

**출력 예시**:
```json
{
  "header": {
    "department": "제선부",
    "doc_number": "TP-030-030-030",
    "revision": "Rev.3",
    "effective_date": "2024.01.15",
    "page": "1/5"
  },
  "elements": [
    {
      "id": "page_1_elem_1",
      "type": "text_header",
      "bbox": {"x": 50, "y": 100, "width": 700, "height": 80},
      "numbering": null,
      "preview": "노열관리 및 보상기준"
    },
    {
      "id": "page_1_elem_2",
      "type": "text_section",
      "bbox": {"x": 50, "y": 200, "width": 700, "height": 150},
      "numbering": "1.",
      "preview": "1. 목적\n이 기준은 고로 조업의..."
    },
    {
      "id": "page_1_elem_3",
      "type": "table",
      "bbox": {"x": 100, "y": 400, "width": 600, "height": 300},
      "numbering": null,
      "preview": "[표 제목] 노열 보상 기준표"
    }
  ],
  "footer": {
    "작성": "홍길동",
    "검토": "김철수",
    "승인": "박영희"
  }
}
```

### Phase 3: 요소별 상세 분석 (Pass 2)

```python
class ElementAnalyzer:
    """요소 타입별 상세 분석"""

    def analyze_element(
        element: ElementDetection,
        page_image: Image,
        context: ContextInfo  # 주변 요소 정보
    ) -> ElementAnalysis:

        # Crop element
        cropped = crop_bbox(page_image, element.bbox)

        # Type-specific prompt
        prompt = self._build_prompt(element.type, context)

        # DeepSeek-OCR analysis
        result = deepseek_ocr.infer(prompt, cropped)

        # Parse structured output
        return self._parse_result(element.type, result)
```

**요소별 프롬프트 전략**:

#### 3.1 텍스트 요소 (text_header/section/paragraph)

```python
PROMPT = """<image>
<|grounding|>Extract from this Korean text block:

1. Full OCR text
2. Numbering (if exists): e.g., "1.", "1.2.", "1.2.3"
3. Structure:
   - Is this a header/section title/paragraph?
   - Hierarchy level (1-5)
4. Keywords: 5-10 most important terms for vector embedding
5. Summary: 1-2 sentence summary (if paragraph)

Return as JSON:
{
  "text": "full OCR text",
  "numbering": "1.2.3" or null,
  "type": "header|section|paragraph",
  "level": 1-5,
  "keywords": ["keyword1", "keyword2", ...],
  "summary": "brief summary" or null
}
"""
```

#### 3.2 표 (Table)

```python
PROMPT = """<image>
Context: {surrounding_text}

<|grounding|>Analyze this Korean table:

1. [항목] Table metadata:
   - Title (if exists)
   - Column headers
   - Row headers
   - Number of rows x columns

2. [키워드] Extract 5-10 keywords from:
   - Table content
   - Surrounding context text
   - Technical terms

3. [자연어 요약] Natural language summary (2-3 sentences):
   - What does this table show?
   - Key data points
   - Trends or patterns

4. Markdown table:
   - Convert to markdown format
   - Preserve cell merges if possible

5. Complexity check:
   - Is this a "complex_image"?
   - Reasons: merged cells, embedded images/graphs, unreadable structure

Return as JSON:
{
  "항목": {
    "title": "...",
    "columns": ["col1", "col2", ...],
    "rows": ["row1", "row2", ...],
    "dimensions": "5x3"
  },
  "키워드": ["keyword1", "keyword2", ...],
  "자연어_요약": "This table shows...",
  "markdown": "| col1 | col2 |\\n|---|---|\\n...",
  "is_complex": false,
  "complexity_reasons": []
}
"""
```

#### 3.3 그래프 (Graph)

```python
PROMPT = """<image>
Context: {surrounding_text}

<|grounding|>Analyze this Korean graph/chart:

1. [항목] Graph components:
   - Title
   - Type (bar/line/pie/box plot/etc.)
   - X-axis label and range
   - Y-axis label and range
   - Legend items
   - Data series names

2. [키워드] Extract keywords from:
   - Graph labels and annotations
   - Surrounding context text
   - Trend terms (증가/감소/변동/등)

3. [자연어 요약] Summary (2-3 sentences):
   - What does this graph show?
   - Key trends (increasing/decreasing/peak/trough)
   - Notable data points

4. Extracted data:
   - If simple, extract key data points
   - Format: {series: [...values...]}

Return as JSON:
{
  "항목": {
    "title": "...",
    "type": "line_chart",
    "x_axis": {"label": "...", "range": "..."},
    "y_axis": {"label": "...", "range": "..."},
    "legend": ["series1", "series2"],
    "annotations": ["text in graph"]
  },
  "키워드": ["keyword1", "keyword2", ...],
  "자연어_요약": "This graph shows...",
  "data": {"series1": [1, 2, 3], "series2": [4, 5, 6]},  // if extractable
  "is_complex": false
}
"""
```

#### 3.4 다이어그램 (Diagram)

```python
PROMPT = """<image>
Context: {surrounding_text}

<|grounding|>Analyze this Korean diagram (flowchart/process diagram):

1. [항목] Diagram components:
   - Shapes: rectangles, circles, diamonds (count and labels)
   - Arrows: flow directions
   - Text in shapes

2. Relationships:
   - Flow direction: left-to-right / top-to-bottom
   - Connections: which shapes connect to which

3. [키워드] Extract keywords from:
   - Shape text
   - Surrounding context
   - Process terms

4. [자연어 요약] Summary (2-3 sentences):
   - What process does this diagram show?
   - Key steps
   - Flow overview

5. Mermaid code:
   - Convert to Mermaid flowchart syntax
   - Use shape text as node labels

6. Complexity check:
   - Count components (if >10, mark as complex_image)
   - Flow clarity (if unclear, mark as complex)

Return as JSON:
{
  "항목": {
    "shapes": [
      {"type": "rectangle", "text": "...", "id": "node1"},
      {"type": "diamond", "text": "...", "id": "node2"}
    ],
    "connections": [
      {"from": "node1", "to": "node2", "label": "예"}
    ],
    "flow_direction": "left_to_right"
  },
  "키워드": ["keyword1", "keyword2", ...],
  "자연어_요약": "This diagram shows...",
  "mermaid": "graph LR\\nA[Step 1] --> B[Step 2]",
  "is_complex": false,
  "component_count": 5
}
"""
```

#### 3.5 복합 이미지 (Complex Image)

```python
PROMPT = """<image>
Context: {surrounding_text}

<|grounding|>Analyze this complex image (MES screen/composite layout):

1. Classify underlying type:
   - Is this fundamentally a table/graph/diagram/screenshot?

2. Extract visible text:
   - All readable text in the image
   - Labels, headers, values

3. [키워드] Extract keywords from:
   - Visible text
   - Surrounding context
   - Inferred purpose

4. [자연어 요약] Summary (3-4 sentences):
   - What is this image?
   - What information does it contain?
   - Why is it complex?

Return as JSON:
{
  "underlying_type": "table|graph|diagram|screenshot|unknown",
  "extracted_text": "all visible text...",
  "키워드": ["keyword1", "keyword2", ...],
  "자연어_요약": "This complex image shows...",
  "complexity_reasons": ["merged cells", "low resolution", "embedded graphs"]
}
"""
```

### Phase 4: 텍스트 병합 및 보강 (Text Merge/Enrichment)

```python
class TextEnricher:
    """분석 결과를 DocJSON 형식으로 통합"""

    def enrich(
        page_structures: List[PageStructure],
        element_analyses: List[ElementAnalysis]
    ) -> DocumentDocJSON:

        # 1. 전역 메타데이터 추출
        metadata = self._extract_global_metadata(page_structures)

        # 2. 섹션 트리 구축 (넘버링 기반)
        sections = self._build_section_tree(element_analyses)

        # 3. ContentBlock 생성
        blocks = []
        for analysis in element_analyses:
            block = self._create_content_block(analysis)

            # 맥락 정보 병합
            if analysis.type in ['table', 'graph', 'diagram']:
                block = self._merge_context(block, analysis.context)

            blocks.append(block)

        # 4. 이미지 저장 및 ID 부여
        self._save_element_images(element_analyses)

        return DocumentDocJSON(
            version="2.0.0",  # 새 버전
            metadata=metadata,
            blocks=blocks,
            sections=sections
        )
```

---

## 🗂️ DocJSON 스키마 확장

### 기존 스키마 분석

**유지할 구조**:
- ✅ `ContentBlock` (flat list)
- ✅ `Section` (tree structure)
- ✅ `DocumentMetadata`
- ✅ `BoundingBox`, `SemanticInfo`

**확장 필요**:
- ⚠️ `ContentBlockType` - 타입 세분화 필요
- ⚠️ `TableData` - Markdown 추가
- ➕ `GraphData` - 새로 추가
- ⚠️ `DiagramData` - Mermaid 추가
- ➕ `ComplexImageData` - 새로 추가
- ➕ `TextBlockData` - 새로 추가 (키워드, 요약)

### 확장된 ContentBlockType

```python
class ContentBlockType(Enum):
    """확장된 콘텐츠 블록 타입"""
    # 기존
    PARAGRAPH = "paragraph"
    TITLE = "title"
    HEADING = "heading"
    TABLE = "table"
    DIAGRAM = "diagram"
    IMAGE = "image"
    LIST = "list"
    CAPTION = "caption"
    FOOTNOTE = "footnote"
    FORMULA = "formula"

    # 새로 추가
    TEXT_HEADER = "text_header"        # 문서 제목
    TEXT_SECTION = "text_section"      # 넘버링 소제목
    TEXT_PARAGRAPH = "text_paragraph"  # 일반 단락
    GRAPH = "graph"                     # 그래프/차트
    COMPLEX_IMAGE = "complex_image"    # 복합 이미지

    # 메타 요소
    DOC_HEADER = "doc_header"          # 문서 헤더 (부서, 문서번호 등)
    DOC_FOOTER = "doc_footer"          # 문서 푸터 (승인자 등)
```

### 새 데이터 타입 정의

```python
@dataclass
class TextBlockData:
    """텍스트 블록 데이터"""
    numbering: Optional[str] = None     # "1.2.3"
    level: int = 1                       # 계층 레벨
    keywords: List[str] = field(default_factory=list)
    summary: Optional[str] = None        # 자연어 요약

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class GraphData:
    """그래프 데이터"""
    title: Optional[str] = None
    graph_type: Optional[str] = None     # "line_chart", "bar_chart", etc.
    x_axis: Dict[str, Any] = field(default_factory=dict)
    y_axis: Dict[str, Any] = field(default_factory=dict)
    legend: List[str] = field(default_factory=list)
    data_series: Dict[str, List] = field(default_factory=dict)

    # 공통 필드
    keywords: List[str] = field(default_factory=list)
    summary: str = ""                    # 자연어 요약
    image_id: Optional[str] = None       # 저장된 이미지 ID

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class ComplexImageData:
    """복합 이미지 데이터"""
    underlying_type: Optional[str] = None  # "table"|"graph"|"diagram"|"screenshot"
    extracted_text: str = ""
    keywords: List[str] = field(default_factory=list)
    summary: str = ""
    complexity_reasons: List[str] = field(default_factory=list)
    image_id: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
```

### 확장된 TableData

```python
@dataclass
class TableData:
    """확장된 테이블 데이터"""
    doc_index: int
    rows: int
    cols: int
    data: List[List[str]]

    # 새로 추가
    title: Optional[str] = None
    markdown: Optional[str] = None       # Markdown 형식 테이블
    keywords: List[str] = field(default_factory=list)
    summary: str = ""                     # 자연어 요약
    image_id: Optional[str] = None        # 저장된 이미지 ID
    is_complex: bool = False              # 복합 이미지 플래그

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
```

### 확장된 DiagramData

```python
@dataclass
class DiagramData:
    """확장된 다이어그램 데이터"""
    id: str
    doc_index: int
    diagram_type: "DiagramType"

    # 기존 필드 유지...

    # 새로 추가
    mermaid: Optional[str] = None         # Mermaid 코드
    keywords: List[str] = field(default_factory=list)
    summary: str = ""                      # 자연어 요약
    image_id: Optional[str] = None         # 저장된 이미지 ID
    component_count: int = 0               # 구성요소 개수
    is_complex: bool = False               # 복합성 플래그
```

### 확장된 ContentBlock

```python
@dataclass
class ContentBlock:
    id: str
    type: ContentBlockType | str
    doc_index: Optional[int] = None
    text: Optional[str] = None
    level: Optional[int] = None
    page: Optional[int] = None

    bbox: Optional[BoundingBox] = None
    semantic: Optional[SemanticInfo] = None

    # 기존 타입별 데이터
    table: Optional[TableData] = None
    list_data: Optional[ListData] = None
    diagram: Optional[DiagramData] = None

    # 새로 추가
    text_block: Optional[TextBlockData] = None        # 텍스트 블록
    graph: Optional[GraphData] = None                  # 그래프
    complex_image: Optional[ComplexImageData] = None  # 복합 이미지
```

---

## 🔄 실행 흐름 요약

```
1. PDF 파싱
   ↓
2. 페이지별 구조 분석 (Pass 1)
   - DeepSeek-OCR <|grounding|> 모드
   - 전체 요소 감지 + Bbox
   ↓
3. 요소별 상세 분석 (Pass 2)
   - 요소 crop
   - 타입별 맞춤 프롬프트
   - [항목], [키워드], [자연어 요약] 추출
   ↓
4. 맥락 병합
   - 주변 텍스트 연결
   - 키워드 통합
   ↓
5. DocJSON 생성
   - 확장된 스키마
   - 섹션 트리 구축
   - 이미지 저장 (ID 부여)
   ↓
6. 벡터 임베딩 준비
   - 키워드 + 요약 → chunking metadata
   - 이미지 ID → 검색 결과 참조
```

---

## 📊 성능 예측

### 처리 시간 (GPU: RTX 4090 기준)

**페이지당**:
- Pass 1 (구조 분석): ~10-15초
- Pass 2 (요소별 분석): 요소당 ~5-10초
- 평균 페이지당 요소: 5-10개
- **총 페이지당**: ~60-100초

**5페이지 문서**:
- **예상 시간**: 5-8분
- **RunPod 비용**: ~$0.06-0.10 (RTX 4090)

### 정확도 목표

- **OCR 정확도**: >95% (한국어)
- **요소 분류 정확도**: >90%
- **Bbox 정확도**: >85%
- **키워드 추출 품질**: 수동 검증 필요

---

## ⚠️ 리스크 및 대응

### Risk 1: DeepSeek-OCR Pass 1이 모든 요소를 놓칠 수 있음

**대응책**:
- ✅ Pass 2에서 추가 검증
- ✅ 사용자 피드백 루프
- ✅ 수동 보정 인터페이스

### Risk 2: 복잡한 표/다이어그램 정확도 낮음

**대응책**:
- ✅ `complex_image` 분류로 우회
- ✅ 사용자에게 원본 이미지 제공
- ✅ 점진적 개선 (피드백 학습)

### Risk 3: 한국어 처리 품질

**대응책**:
- ✅ 프롬프트에 "Korean" 명시
- ✅ 샘플 테스트 후 프롬프트 튜닝
- ✅ 필요시 번역 후처리

### Risk 4: RunPod 비용

**대응책**:
- ✅ Spot 인스턴스 사용
- ✅ 배치 처리 최적화
- ✅ 캐싱 전략

---

## 다음 단계

1. ✅ **프롬프트 엔지니어링** - 각 타입별 프롬프트 정제
2. ✅ **DocJSON 스키마 확장** - 새 데이터 타입 구현
3. ✅ **파이프라인 구현** - 2-Pass 전략 코드화
4. ⏳ **RunPod 테스트** - 실제 문서로 검증
5. ⏳ **정확도 평가** - 수동 검증 및 개선

---

**이 계획은 DeepSeek-OCR의 능력을 최대한 활용하여, 별도 OCR이나 레이아웃 분석 모델 없이 전체 파이프라인을 구축하는 것을 목표로 합니다.**
