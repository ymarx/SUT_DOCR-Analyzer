# DeepSeek-OCR ì „ìš© íŒŒì´í”„ë¼ì¸ ë§ˆìŠ¤í„° í”Œëœ
**ì‘ì„±ì¼**: 2025-10-23
**ëª©í‘œ**: DeepSeek-OCRì˜ `<|grounding|>` ëŠ¥ë ¥ë§Œìœ¼ë¡œ ìŠ¤ìº” PDF ì „ì²´ ì²˜ë¦¬

---

## ğŸ§  í•µì‹¬ ì „ëµ (Deep Thinking)

### 1. DeepSeek-OCRì˜ ëŠ¥ë ¥ ì¬ì •ì˜

**í™•ì¸ëœ ëŠ¥ë ¥**:
- âœ… **Bounding Box ê²€ì¶œ** (`<|grounding|>` ëª¨ë“œ)
- âœ… **ë ˆì´ì•„ì›ƒ ì¸ì‹** (SAM-base + CLIP-large)
- âœ… **ìš”ì†Œ ë¶„ë¥˜** (í…ìŠ¤íŠ¸/í‘œ/ê·¸ë˜í”„/ë‹¤ì´ì–´ê·¸ë¨)
- âœ… **êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ** (Markdown í…Œì´ë¸”, JSON)
- âœ… **ë§¥ë½ ì´í•´** (ì£¼ë³€ í…ìŠ¤íŠ¸ ì—°ê²°)
- âœ… **OCR** (í…ìŠ¤íŠ¸ ë ˆì´ì–´ ì—†ëŠ” ìŠ¤ìº” ë¬¸ì„œ)

**ì œí•œì‚¬í•­**:
- âŒ í•œ ë²ˆì— ì „ì²´ í˜ì´ì§€ì˜ ëª¨ë“  ìš”ì†Œë¥¼ bboxê¹Œì§€ ì •í™•íˆ ì¶”ì¶œí•˜ëŠ” ê²ƒì€ ë¶ˆí™•ì‹¤
- âš ï¸ ë³µì¡í•œ ë ˆì´ì•„ì›ƒì—ì„œ bbox ì •í™•ë„ ê²€ì¦ í•„ìš”
- âš ï¸ í•œêµ­ì–´ ì²˜ë¦¬ ì„±ëŠ¥ ê²€ì¦ í•„ìš”

### 2. ë¬¸ì„œ êµ¬ì¡° ë¶„ì„

**SUT ê¸°ìˆ  ë¬¸ì„œ íŠ¹ì„±** (TP-030-030-030.pdf ê¸°ì¤€):
```
[ê³ ì • í—¤ë”]
- ë¶€ì„œëª…, ë¬¸ì„œë²ˆí˜¸, Rev., ì‘ì„±ì¼, í˜ì´ì§€ ë“±

[ë³¸ë¬¸ êµ¬ì¡°]
- ë„˜ë²„ë§ ì œëª© (1., 1.1., 1.1.1.)
- í…ìŠ¤íŠ¸ ë‹¨ë½
- í‘œ (ì •í˜•/ë¹„ì •í˜•)
- ê·¸ë˜í”„ (ë§‰ëŒ€/ì„ /íŒŒì´)
- ë‹¤ì´ì–´ê·¸ë¨ (ê³µì •ë„/ìˆœì„œë„)
- ë³µí•© ì´ë¯¸ì§€ (MES í™”ë©´ ìº¡ì²˜ ë“±)

[ê³ ì • í‘¸í„°]
- ìŠ¹ì¸ì, ê²€í† ì ì •ë³´
```

### 3. 2ë‹¨ê³„ ì¶”ì¶œ ì „ëµ

**ë¬¸ì œ**: DeepSeek-OCRì´ í•œ ë²ˆì— ëª¨ë“  ìš”ì†Œë¥¼ ì •í™•íˆ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ”ì§€ ë¶ˆí™•ì‹¤

**í•´ê²°ì±…**: **2-Pass ì „ëµ**

**Pass 1: ì „ì²´ í˜ì´ì§€ êµ¬ì¡° ë¶„ì„** (í˜ì´ì§€ë‹¹ 1íšŒ)
```python
prompt = """<image>
<|grounding|>Analyze this Korean steel mill technical document page:

1. Detect ALL visual elements with bounding boxes:
   - Text blocks (headers, sections, paragraphs with numbering)
   - Tables
   - Graphs/Charts
   - Diagrams (flowcharts, process diagrams)
   - Complex images (MES screens, composite layouts)

2. Extract document structure:
   - Page header (department, doc number, revision, date, page number)
   - Numbered sections (1., 1.1., 1.1.1., etc.)
   - Page footer (approvers, reviewers)

3. Return as structured JSON:
{
  "header": {"department": "...", "doc_number": "...", ...},
  "elements": [
    {
      "id": "elem_1",
      "type": "text_section",  // text_header|text_section|text_paragraph|table|graph|diagram|complex_image
      "bbox": {"x": 100, "y": 200, "width": 800, "height": 150, "page": 1},
      "numbering": "1.2.3",  // if applicable
      "preview": "ì²« 50ì í…ìŠ¤íŠ¸..."
    },
    ...
  ],
  "footer": {"approver": "...", "reviewer": "..."}
}
"""
```

**Pass 2: ìš”ì†Œë³„ ìƒì„¸ ë¶„ì„** (ìš”ì†Œë‹¹ 1íšŒ)
```python
# ê° ìš”ì†Œë¥¼ cropí•˜ì—¬ ê°œë³„ ë¶„ì„
for element in elements:
    cropped_image = crop_bbox(page_image, element['bbox'])

    if element['type'] == 'table':
        prompt = table_analysis_prompt(element, context)
    elif element['type'] == 'graph':
        prompt = graph_analysis_prompt(element, context)
    elif element['type'] == 'diagram':
        prompt = diagram_analysis_prompt(element, context)
    # ...

    analysis = deepseek_ocr.analyze(cropped_image, prompt)
```

**ì¥ì **:
- âœ… 1ì°¨ Pass: ë¹ ë¥¸ ì „ì²´ êµ¬ì¡° íŒŒì•…
- âœ… 2ì°¨ Pass: ìš”ì†Œë³„ ì •ë°€ ë¶„ì„ (ë§¥ë½ ì •ë³´ í¬í•¨)
- âœ… Bbox ì¬ì‚¬ìš©: ìš”ì†Œ crop, ì €ì¥, ê²€ìƒ‰ì— í™œìš©

---

## ğŸ“‹ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì„¤ê³„

### Phase 1: PDF â†’ í˜ì´ì§€ ì´ë¯¸ì§€

```python
class PDFParser:
    def parse(pdf_path) -> List[PageImage]:
        # PyMuPDF + pdf2image
        # DPI: 200 (ì†ë„ì™€ í’ˆì§ˆ ê· í˜•)
        return page_images
```

### Phase 2: ì „ì²´ í˜ì´ì§€ êµ¬ì¡° ë¶„ì„ (Pass 1)

```python
class PageStructureAnalyzer:
    """DeepSeek-OCR <|grounding|> ëª¨ë“œë¡œ ì „ì²´ í˜ì´ì§€ êµ¬ì¡° ì¶”ì¶œ"""

    def analyze_page_structure(page_image) -> PageStructure:
        prompt = STRUCTURE_ANALYSIS_PROMPT
        result = deepseek_ocr.infer(prompt, page_image)

        return PageStructure(
            header=DocumentHeader(...),
            elements=List[ElementDetection],  # type, bbox, preview
            footer=DocumentFooter(...)
        )
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```json
{
  "header": {
    "department": "ì œì„ ë¶€",
    "doc_number": "TP-030-030-030",
    "revision": "Rev.3",
    "effective_date": "2024.01.15",
    "page": "1/5"
  },
  "elements": [
    {
      "id": "page_1_elem_1",
      "type": "text_header",
      "bbox": {"x": 50, "y": 100, "width": 700, "height": 80},
      "numbering": null,
      "preview": "ë…¸ì—´ê´€ë¦¬ ë° ë³´ìƒê¸°ì¤€"
    },
    {
      "id": "page_1_elem_2",
      "type": "text_section",
      "bbox": {"x": 50, "y": 200, "width": 700, "height": 150},
      "numbering": "1.",
      "preview": "1. ëª©ì \nì´ ê¸°ì¤€ì€ ê³ ë¡œ ì¡°ì—…ì˜..."
    },
    {
      "id": "page_1_elem_3",
      "type": "table",
      "bbox": {"x": 100, "y": 400, "width": 600, "height": 300},
      "numbering": null,
      "preview": "[í‘œ ì œëª©] ë…¸ì—´ ë³´ìƒ ê¸°ì¤€í‘œ"
    }
  ],
  "footer": {
    "ì‘ì„±": "í™ê¸¸ë™",
    "ê²€í† ": "ê¹€ì² ìˆ˜",
    "ìŠ¹ì¸": "ë°•ì˜í¬"
  }
}
```

### Phase 3: ìš”ì†Œë³„ ìƒì„¸ ë¶„ì„ (Pass 2)

```python
class ElementAnalyzer:
    """ìš”ì†Œ íƒ€ì…ë³„ ìƒì„¸ ë¶„ì„"""

    def analyze_element(
        element: ElementDetection,
        page_image: Image,
        context: ContextInfo  # ì£¼ë³€ ìš”ì†Œ ì •ë³´
    ) -> ElementAnalysis:

        # Crop element
        cropped = crop_bbox(page_image, element.bbox)

        # Type-specific prompt
        prompt = self._build_prompt(element.type, context)

        # DeepSeek-OCR analysis
        result = deepseek_ocr.infer(prompt, cropped)

        # Parse structured output
        return self._parse_result(element.type, result)
```

**ìš”ì†Œë³„ í”„ë¡¬í”„íŠ¸ ì „ëµ**:

#### 3.1 í…ìŠ¤íŠ¸ ìš”ì†Œ (text_header/section/paragraph)

```python
PROMPT = """<image>
<|grounding|>Extract from this Korean text block:

1. Full OCR text
2. Numbering (if exists): e.g., "1.", "1.2.", "1.2.3"
3. Structure:
   - Is this a header/section title/paragraph?
   - Hierarchy level (1-5)
4. Keywords: 5-10 most important terms for vector embedding
5. Summary: 1-2 sentence summary (if paragraph)

Return as JSON:
{
  "text": "full OCR text",
  "numbering": "1.2.3" or null,
  "type": "header|section|paragraph",
  "level": 1-5,
  "keywords": ["keyword1", "keyword2", ...],
  "summary": "brief summary" or null
}
"""
```

#### 3.2 í‘œ (Table)

```python
PROMPT = """<image>
Context: {surrounding_text}

<|grounding|>Analyze this Korean table:

1. [í•­ëª©] Table metadata:
   - Title (if exists)
   - Column headers
   - Row headers
   - Number of rows x columns

2. [í‚¤ì›Œë“œ] Extract 5-10 keywords from:
   - Table content
   - Surrounding context text
   - Technical terms

3. [ìì—°ì–´ ìš”ì•½] Natural language summary (2-3 sentences):
   - What does this table show?
   - Key data points
   - Trends or patterns

4. Markdown table:
   - Convert to markdown format
   - Preserve cell merges if possible

5. Complexity check:
   - Is this a "complex_image"?
   - Reasons: merged cells, embedded images/graphs, unreadable structure

Return as JSON:
{
  "í•­ëª©": {
    "title": "...",
    "columns": ["col1", "col2", ...],
    "rows": ["row1", "row2", ...],
    "dimensions": "5x3"
  },
  "í‚¤ì›Œë“œ": ["keyword1", "keyword2", ...],
  "ìì—°ì–´_ìš”ì•½": "This table shows...",
  "markdown": "| col1 | col2 |\\n|---|---|\\n...",
  "is_complex": false,
  "complexity_reasons": []
}
"""
```

#### 3.3 ê·¸ë˜í”„ (Graph)

```python
PROMPT = """<image>
Context: {surrounding_text}

<|grounding|>Analyze this Korean graph/chart:

1. [í•­ëª©] Graph components:
   - Title
   - Type (bar/line/pie/box plot/etc.)
   - X-axis label and range
   - Y-axis label and range
   - Legend items
   - Data series names

2. [í‚¤ì›Œë“œ] Extract keywords from:
   - Graph labels and annotations
   - Surrounding context text
   - Trend terms (ì¦ê°€/ê°ì†Œ/ë³€ë™/ë“±)

3. [ìì—°ì–´ ìš”ì•½] Summary (2-3 sentences):
   - What does this graph show?
   - Key trends (increasing/decreasing/peak/trough)
   - Notable data points

4. Extracted data:
   - If simple, extract key data points
   - Format: {series: [...values...]}

Return as JSON:
{
  "í•­ëª©": {
    "title": "...",
    "type": "line_chart",
    "x_axis": {"label": "...", "range": "..."},
    "y_axis": {"label": "...", "range": "..."},
    "legend": ["series1", "series2"],
    "annotations": ["text in graph"]
  },
  "í‚¤ì›Œë“œ": ["keyword1", "keyword2", ...],
  "ìì—°ì–´_ìš”ì•½": "This graph shows...",
  "data": {"series1": [1, 2, 3], "series2": [4, 5, 6]},  // if extractable
  "is_complex": false
}
"""
```

#### 3.4 ë‹¤ì´ì–´ê·¸ë¨ (Diagram)

```python
PROMPT = """<image>
Context: {surrounding_text}

<|grounding|>Analyze this Korean diagram (flowchart/process diagram):

1. [í•­ëª©] Diagram components:
   - Shapes: rectangles, circles, diamonds (count and labels)
   - Arrows: flow directions
   - Text in shapes

2. Relationships:
   - Flow direction: left-to-right / top-to-bottom
   - Connections: which shapes connect to which

3. [í‚¤ì›Œë“œ] Extract keywords from:
   - Shape text
   - Surrounding context
   - Process terms

4. [ìì—°ì–´ ìš”ì•½] Summary (2-3 sentences):
   - What process does this diagram show?
   - Key steps
   - Flow overview

5. Mermaid code:
   - Convert to Mermaid flowchart syntax
   - Use shape text as node labels

6. Complexity check:
   - Count components (if >10, mark as complex_image)
   - Flow clarity (if unclear, mark as complex)

Return as JSON:
{
  "í•­ëª©": {
    "shapes": [
      {"type": "rectangle", "text": "...", "id": "node1"},
      {"type": "diamond", "text": "...", "id": "node2"}
    ],
    "connections": [
      {"from": "node1", "to": "node2", "label": "ì˜ˆ"}
    ],
    "flow_direction": "left_to_right"
  },
  "í‚¤ì›Œë“œ": ["keyword1", "keyword2", ...],
  "ìì—°ì–´_ìš”ì•½": "This diagram shows...",
  "mermaid": "graph LR\\nA[Step 1] --> B[Step 2]",
  "is_complex": false,
  "component_count": 5
}
"""
```

#### 3.5 ë³µí•© ì´ë¯¸ì§€ (Complex Image)

```python
PROMPT = """<image>
Context: {surrounding_text}

<|grounding|>Analyze this complex image (MES screen/composite layout):

1. Classify underlying type:
   - Is this fundamentally a table/graph/diagram/screenshot?

2. Extract visible text:
   - All readable text in the image
   - Labels, headers, values

3. [í‚¤ì›Œë“œ] Extract keywords from:
   - Visible text
   - Surrounding context
   - Inferred purpose

4. [ìì—°ì–´ ìš”ì•½] Summary (3-4 sentences):
   - What is this image?
   - What information does it contain?
   - Why is it complex?

Return as JSON:
{
  "underlying_type": "table|graph|diagram|screenshot|unknown",
  "extracted_text": "all visible text...",
  "í‚¤ì›Œë“œ": ["keyword1", "keyword2", ...],
  "ìì—°ì–´_ìš”ì•½": "This complex image shows...",
  "complexity_reasons": ["merged cells", "low resolution", "embedded graphs"]
}
"""
```

### Phase 4: í…ìŠ¤íŠ¸ ë³‘í•© ë° ë³´ê°• (Text Merge/Enrichment)

```python
class TextEnricher:
    """ë¶„ì„ ê²°ê³¼ë¥¼ DocJSON í˜•ì‹ìœ¼ë¡œ í†µí•©"""

    def enrich(
        page_structures: List[PageStructure],
        element_analyses: List[ElementAnalysis]
    ) -> DocumentDocJSON:

        # 1. ì „ì—­ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata = self._extract_global_metadata(page_structures)

        # 2. ì„¹ì…˜ íŠ¸ë¦¬ êµ¬ì¶• (ë„˜ë²„ë§ ê¸°ë°˜)
        sections = self._build_section_tree(element_analyses)

        # 3. ContentBlock ìƒì„±
        blocks = []
        for analysis in element_analyses:
            block = self._create_content_block(analysis)

            # ë§¥ë½ ì •ë³´ ë³‘í•©
            if analysis.type in ['table', 'graph', 'diagram']:
                block = self._merge_context(block, analysis.context)

            blocks.append(block)

        # 4. ì´ë¯¸ì§€ ì €ì¥ ë° ID ë¶€ì—¬
        self._save_element_images(element_analyses)

        return DocumentDocJSON(
            version="2.0.0",  # ìƒˆ ë²„ì „
            metadata=metadata,
            blocks=blocks,
            sections=sections
        )
```

---

## ğŸ—‚ï¸ DocJSON ìŠ¤í‚¤ë§ˆ í™•ì¥

### ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ ë¶„ì„

**ìœ ì§€í•  êµ¬ì¡°**:
- âœ… `ContentBlock` (flat list)
- âœ… `Section` (tree structure)
- âœ… `DocumentMetadata`
- âœ… `BoundingBox`, `SemanticInfo`

**í™•ì¥ í•„ìš”**:
- âš ï¸ `ContentBlockType` - íƒ€ì… ì„¸ë¶„í™” í•„ìš”
- âš ï¸ `TableData` - Markdown ì¶”ê°€
- â• `GraphData` - ìƒˆë¡œ ì¶”ê°€
- âš ï¸ `DiagramData` - Mermaid ì¶”ê°€
- â• `ComplexImageData` - ìƒˆë¡œ ì¶”ê°€
- â• `TextBlockData` - ìƒˆë¡œ ì¶”ê°€ (í‚¤ì›Œë“œ, ìš”ì•½)

### í™•ì¥ëœ ContentBlockType

```python
class ContentBlockType(Enum):
    """í™•ì¥ëœ ì½˜í…ì¸  ë¸”ë¡ íƒ€ì…"""
    # ê¸°ì¡´
    PARAGRAPH = "paragraph"
    TITLE = "title"
    HEADING = "heading"
    TABLE = "table"
    DIAGRAM = "diagram"
    IMAGE = "image"
    LIST = "list"
    CAPTION = "caption"
    FOOTNOTE = "footnote"
    FORMULA = "formula"

    # ìƒˆë¡œ ì¶”ê°€
    TEXT_HEADER = "text_header"        # ë¬¸ì„œ ì œëª©
    TEXT_SECTION = "text_section"      # ë„˜ë²„ë§ ì†Œì œëª©
    TEXT_PARAGRAPH = "text_paragraph"  # ì¼ë°˜ ë‹¨ë½
    GRAPH = "graph"                     # ê·¸ë˜í”„/ì°¨íŠ¸
    COMPLEX_IMAGE = "complex_image"    # ë³µí•© ì´ë¯¸ì§€

    # ë©”íƒ€ ìš”ì†Œ
    DOC_HEADER = "doc_header"          # ë¬¸ì„œ í—¤ë” (ë¶€ì„œ, ë¬¸ì„œë²ˆí˜¸ ë“±)
    DOC_FOOTER = "doc_footer"          # ë¬¸ì„œ í‘¸í„° (ìŠ¹ì¸ì ë“±)
```

### ìƒˆ ë°ì´í„° íƒ€ì… ì •ì˜

```python
@dataclass
class TextBlockData:
    """í…ìŠ¤íŠ¸ ë¸”ë¡ ë°ì´í„°"""
    numbering: Optional[str] = None     # "1.2.3"
    level: int = 1                       # ê³„ì¸µ ë ˆë²¨
    keywords: List[str] = field(default_factory=list)
    summary: Optional[str] = None        # ìì—°ì–´ ìš”ì•½

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class GraphData:
    """ê·¸ë˜í”„ ë°ì´í„°"""
    title: Optional[str] = None
    graph_type: Optional[str] = None     # "line_chart", "bar_chart", etc.
    x_axis: Dict[str, Any] = field(default_factory=dict)
    y_axis: Dict[str, Any] = field(default_factory=dict)
    legend: List[str] = field(default_factory=list)
    data_series: Dict[str, List] = field(default_factory=dict)

    # ê³µí†µ í•„ë“œ
    keywords: List[str] = field(default_factory=list)
    summary: str = ""                    # ìì—°ì–´ ìš”ì•½
    image_id: Optional[str] = None       # ì €ì¥ëœ ì´ë¯¸ì§€ ID

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class ComplexImageData:
    """ë³µí•© ì´ë¯¸ì§€ ë°ì´í„°"""
    underlying_type: Optional[str] = None  # "table"|"graph"|"diagram"|"screenshot"
    extracted_text: str = ""
    keywords: List[str] = field(default_factory=list)
    summary: str = ""
    complexity_reasons: List[str] = field(default_factory=list)
    image_id: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
```

### í™•ì¥ëœ TableData

```python
@dataclass
class TableData:
    """í™•ì¥ëœ í…Œì´ë¸” ë°ì´í„°"""
    doc_index: int
    rows: int
    cols: int
    data: List[List[str]]

    # ìƒˆë¡œ ì¶”ê°€
    title: Optional[str] = None
    markdown: Optional[str] = None       # Markdown í˜•ì‹ í…Œì´ë¸”
    keywords: List[str] = field(default_factory=list)
    summary: str = ""                     # ìì—°ì–´ ìš”ì•½
    image_id: Optional[str] = None        # ì €ì¥ëœ ì´ë¯¸ì§€ ID
    is_complex: bool = False              # ë³µí•© ì´ë¯¸ì§€ í”Œë˜ê·¸

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
```

### í™•ì¥ëœ DiagramData

```python
@dataclass
class DiagramData:
    """í™•ì¥ëœ ë‹¤ì´ì–´ê·¸ë¨ ë°ì´í„°"""
    id: str
    doc_index: int
    diagram_type: "DiagramType"

    # ê¸°ì¡´ í•„ë“œ ìœ ì§€...

    # ìƒˆë¡œ ì¶”ê°€
    mermaid: Optional[str] = None         # Mermaid ì½”ë“œ
    keywords: List[str] = field(default_factory=list)
    summary: str = ""                      # ìì—°ì–´ ìš”ì•½
    image_id: Optional[str] = None         # ì €ì¥ëœ ì´ë¯¸ì§€ ID
    component_count: int = 0               # êµ¬ì„±ìš”ì†Œ ê°œìˆ˜
    is_complex: bool = False               # ë³µí•©ì„± í”Œë˜ê·¸
```

### í™•ì¥ëœ ContentBlock

```python
@dataclass
class ContentBlock:
    id: str
    type: ContentBlockType | str
    doc_index: Optional[int] = None
    text: Optional[str] = None
    level: Optional[int] = None
    page: Optional[int] = None

    bbox: Optional[BoundingBox] = None
    semantic: Optional[SemanticInfo] = None

    # ê¸°ì¡´ íƒ€ì…ë³„ ë°ì´í„°
    table: Optional[TableData] = None
    list_data: Optional[ListData] = None
    diagram: Optional[DiagramData] = None

    # ìƒˆë¡œ ì¶”ê°€
    text_block: Optional[TextBlockData] = None        # í…ìŠ¤íŠ¸ ë¸”ë¡
    graph: Optional[GraphData] = None                  # ê·¸ë˜í”„
    complex_image: Optional[ComplexImageData] = None  # ë³µí•© ì´ë¯¸ì§€
```

---

## ğŸ”„ ì‹¤í–‰ íë¦„ ìš”ì•½

```
1. PDF íŒŒì‹±
   â†“
2. í˜ì´ì§€ë³„ êµ¬ì¡° ë¶„ì„ (Pass 1)
   - DeepSeek-OCR <|grounding|> ëª¨ë“œ
   - ì „ì²´ ìš”ì†Œ ê°ì§€ + Bbox
   â†“
3. ìš”ì†Œë³„ ìƒì„¸ ë¶„ì„ (Pass 2)
   - ìš”ì†Œ crop
   - íƒ€ì…ë³„ ë§ì¶¤ í”„ë¡¬í”„íŠ¸
   - [í•­ëª©], [í‚¤ì›Œë“œ], [ìì—°ì–´ ìš”ì•½] ì¶”ì¶œ
   â†“
4. ë§¥ë½ ë³‘í•©
   - ì£¼ë³€ í…ìŠ¤íŠ¸ ì—°ê²°
   - í‚¤ì›Œë“œ í†µí•©
   â†“
5. DocJSON ìƒì„±
   - í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ
   - ì„¹ì…˜ íŠ¸ë¦¬ êµ¬ì¶•
   - ì´ë¯¸ì§€ ì €ì¥ (ID ë¶€ì—¬)
   â†“
6. ë²¡í„° ì„ë² ë”© ì¤€ë¹„
   - í‚¤ì›Œë“œ + ìš”ì•½ â†’ chunking metadata
   - ì´ë¯¸ì§€ ID â†’ ê²€ìƒ‰ ê²°ê³¼ ì°¸ì¡°
```

---

## ğŸ“Š ì„±ëŠ¥ ì˜ˆì¸¡

### ì²˜ë¦¬ ì‹œê°„ (GPU: RTX 4090 ê¸°ì¤€)

**í˜ì´ì§€ë‹¹**:
- Pass 1 (êµ¬ì¡° ë¶„ì„): ~10-15ì´ˆ
- Pass 2 (ìš”ì†Œë³„ ë¶„ì„): ìš”ì†Œë‹¹ ~5-10ì´ˆ
- í‰ê·  í˜ì´ì§€ë‹¹ ìš”ì†Œ: 5-10ê°œ
- **ì´ í˜ì´ì§€ë‹¹**: ~60-100ì´ˆ

**5í˜ì´ì§€ ë¬¸ì„œ**:
- **ì˜ˆìƒ ì‹œê°„**: 5-8ë¶„
- **RunPod ë¹„ìš©**: ~$0.06-0.10 (RTX 4090)

### ì •í™•ë„ ëª©í‘œ

- **OCR ì •í™•ë„**: >95% (í•œêµ­ì–´)
- **ìš”ì†Œ ë¶„ë¥˜ ì •í™•ë„**: >90%
- **Bbox ì •í™•ë„**: >85%
- **í‚¤ì›Œë“œ ì¶”ì¶œ í’ˆì§ˆ**: ìˆ˜ë™ ê²€ì¦ í•„ìš”

---

## âš ï¸ ë¦¬ìŠ¤í¬ ë° ëŒ€ì‘

### Risk 1: DeepSeek-OCR Pass 1ì´ ëª¨ë“  ìš”ì†Œë¥¼ ë†“ì¹  ìˆ˜ ìˆìŒ

**ëŒ€ì‘ì±…**:
- âœ… Pass 2ì—ì„œ ì¶”ê°€ ê²€ì¦
- âœ… ì‚¬ìš©ì í”¼ë“œë°± ë£¨í”„
- âœ… ìˆ˜ë™ ë³´ì • ì¸í„°í˜ì´ìŠ¤

### Risk 2: ë³µì¡í•œ í‘œ/ë‹¤ì´ì–´ê·¸ë¨ ì •í™•ë„ ë‚®ìŒ

**ëŒ€ì‘ì±…**:
- âœ… `complex_image` ë¶„ë¥˜ë¡œ ìš°íšŒ
- âœ… ì‚¬ìš©ìì—ê²Œ ì›ë³¸ ì´ë¯¸ì§€ ì œê³µ
- âœ… ì ì§„ì  ê°œì„  (í”¼ë“œë°± í•™ìŠµ)

### Risk 3: í•œêµ­ì–´ ì²˜ë¦¬ í’ˆì§ˆ

**ëŒ€ì‘ì±…**:
- âœ… í”„ë¡¬í”„íŠ¸ì— "Korean" ëª…ì‹œ
- âœ… ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ í›„ í”„ë¡¬í”„íŠ¸ íŠœë‹
- âœ… í•„ìš”ì‹œ ë²ˆì—­ í›„ì²˜ë¦¬

### Risk 4: RunPod ë¹„ìš©

**ëŒ€ì‘ì±…**:
- âœ… Spot ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
- âœ… ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
- âœ… ìºì‹± ì „ëµ

---

## ë‹¤ìŒ ë‹¨ê³„

1. âœ… **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§** - ê° íƒ€ì…ë³„ í”„ë¡¬í”„íŠ¸ ì •ì œ
2. âœ… **DocJSON ìŠ¤í‚¤ë§ˆ í™•ì¥** - ìƒˆ ë°ì´í„° íƒ€ì… êµ¬í˜„
3. âœ… **íŒŒì´í”„ë¼ì¸ êµ¬í˜„** - 2-Pass ì „ëµ ì½”ë“œí™”
4. â³ **RunPod í…ŒìŠ¤íŠ¸** - ì‹¤ì œ ë¬¸ì„œë¡œ ê²€ì¦
5. â³ **ì •í™•ë„ í‰ê°€** - ìˆ˜ë™ ê²€ì¦ ë° ê°œì„ 

---

**ì´ ê³„íšì€ DeepSeek-OCRì˜ ëŠ¥ë ¥ì„ ìµœëŒ€í•œ í™œìš©í•˜ì—¬, ë³„ë„ OCRì´ë‚˜ ë ˆì´ì•„ì›ƒ ë¶„ì„ ëª¨ë¸ ì—†ì´ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.**
