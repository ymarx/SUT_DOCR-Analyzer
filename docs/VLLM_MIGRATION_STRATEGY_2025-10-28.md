# vLLM ê¸°ë°˜ êµ¬ì¡° ì „í™˜ ì „ëµ ë¬¸ì„œ
**ì‘ì„±ì¼**: 2025-10-28
**ëª©ì **: HuggingFace Transformers â†’ vLLM ê¸°ë°˜ ê³ ì† ì¶”ë¡  êµ¬ì¡°ë¡œ ì „í™˜

---

## ğŸ¯ ì „í™˜ ëª©í‘œ

### 1. ì„±ëŠ¥ ìµœì í™”
- **ì¶”ë¡  ì†ë„**: vLLMì€ HF Transformers ëŒ€ë¹„ 3-5ë°° ë¹ ë¦„
- **ë©”ëª¨ë¦¬ íš¨ìœ¨**: PagedAttentionìœ¼ë¡œ ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë°©ì§€
- **ë°°ì¹˜ ì²˜ë¦¬**: ë™ì  ë°°ì¹˜ ì²˜ë¦¬ë¡œ GPU í™œìš©ë¥  ê·¹ëŒ€í™”
- **í™•ì¥ì„±**: 19í˜ì´ì§€ PDF ì²˜ë¦¬ ì‹œê°„ ëŒ€í­ ë‹¨ì¶• (ì˜ˆìƒ: 5ë¶„ â†’ 2ë¶„ ì´ë‚´)

### 2. ê³µì‹ ë°©ì‹ ì¤€ìˆ˜
- **ê³µì‹ vLLM ì˜ˆì œ**: `DeepSeek-OCR-vllm/run_dpsk_ocr_pdf.py` ê¸°ë°˜
- **ê²€ì¦ëœ êµ¬í˜„**: ê³µì‹ ë ˆí¬ì§€í† ë¦¬ì˜ í”„ë¡œë•ì…˜ ì½”ë“œ í™œìš©
- **ì•ˆì •ì„±**: ì´ë¯¸ ê²€ì¦ëœ ì„¤ì •ê³¼ íŒŒë¼ë¯¸í„° ì‚¬ìš©

### 3. í”„ë¡œì íŠ¸ ëª©í‘œ ìœ ì§€
- âœ… ë²¡í„° ê²€ìƒ‰ ìµœì í™” (ê·¸ë˜í”„/ë„í‘œ ìì—°ì–´ ìš”ì•½)
- âœ… 7ê°œ ìš”ì†Œ ë¶„ë¥˜ + ì£¼ë³€ ì •ë³´ í™œìš©
- âœ… í‚¤ì›Œë“œ/ìì—°ì–´ ìš”ì•½ ìƒì„±
- âœ… 2-Pass íŒŒì´í”„ë¼ì¸ ìœ ì§€

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ë¹„êµ

### í˜„ì¬ êµ¬ì¡° (HF Transformers)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DeepSeekEngine (HF Transformers)        â”‚
â”‚ - AutoModel.from_pretrained()           â”‚
â”‚ - model.infer() ì§ì ‘ í˜¸ì¶œ               â”‚
â”‚ - ìˆœì°¨ ì²˜ë¦¬ (í˜ì´ì§€ë³„)                  â”‚
â”‚ - output_path ì„ì‹œ ë””ë ‰í† ë¦¬ í•„ìš”        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2-Pass Pipeline                          â”‚
â”‚ Pass 1: infer_structure() 19íšŒ           â”‚
â”‚ Pass 2: infer_element() NíšŒ              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ëª©í‘œ êµ¬ì¡° (vLLM)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DeepSeekVLLMEngine (vLLM)               â”‚
â”‚ - LLM() ì´ˆê¸°í™” (1íšŒ)                    â”‚
â”‚ - llm.generate() ë°°ì¹˜ ì²˜ë¦¬              â”‚
â”‚ - ë³‘ë ¬ ì²˜ë¦¬ (MAX_CONCURRENCY)           â”‚
â”‚ - PagedAttention ë©”ëª¨ë¦¬ ìµœì í™”          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2-Pass Pipeline (vLLM ìµœì í™”)           â”‚
â”‚ Pass 1: ë°°ì¹˜ ì²˜ë¦¬ (19 í˜ì´ì§€ ë™ì‹œ)      â”‚
â”‚ Pass 2: ë°°ì¹˜ ì²˜ë¦¬ (N ìš”ì†Œ ë™ì‹œ)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” ì£¼ìš” ì°¨ì´ì  ë¶„ì„

### HF Transformers vs vLLM API

| í•­ëª© | HF Transformers | vLLM |
|------|-----------------|------|
| **ëª¨ë¸ ë¡œë”©** | `AutoModel.from_pretrained()` | `LLM(model=..., hf_overrides=...)` |
| **ì¶”ë¡  í˜¸ì¶œ** | `model.infer(tokenizer, prompt, image_file, output_path, ...)` | `llm.generate(batch_inputs, sampling_params)` |
| **ì´ë¯¸ì§€ ì „ì²˜ë¦¬** | ë‚´ë¶€ ìë™ ì²˜ë¦¬ | ëª…ì‹œì  `DeepseekOCRProcessor()` í˜¸ì¶œ |
| **ë°°ì¹˜ ì²˜ë¦¬** | ìˆœì°¨ ì²˜ë¦¬ (ë£¨í”„) | ë™ì  ë°°ì¹˜ ì²˜ë¦¬ |
| **output_path** | í•„ìˆ˜ (mkdir í˜¸ì¶œ) | ì„ íƒì  (í›„ì²˜ë¦¬ìš©) |
| **í”„ë¡¬í”„íŠ¸ í˜•ì‹** | ë¬¸ìì—´ ì§ì ‘ ì „ë‹¬ | `{"prompt": ..., "multi_modal_data": ...}` dict |

### í•µì‹¬ ë³€ê²½ ì‚¬í•­

#### 1. ëª¨ë¸ ì´ˆê¸°í™”
**HF Transformers**:
```python
self.model = AutoModel.from_pretrained(
    model_name,
    cache_dir=cache_dir,
    torch_dtype=torch.float16,
    device_map={"": 0},
    trust_remote_code=True,
)
```

**vLLM**:
```python
from vllm.model_executor.models.registry import ModelRegistry
from deepseek_ocr import DeepseekOCRForCausalLM

ModelRegistry.register_model("DeepseekOCRForCausalLM", DeepseekOCRForCausalLM)

llm = LLM(
    model="deepseek-ai/DeepSeek-OCR",
    hf_overrides={"architectures": ["DeepseekOCRForCausalLM"]},
    block_size=256,
    enforce_eager=False,
    trust_remote_code=True,
    max_model_len=8192,
    swap_space=0,
    max_num_seqs=MAX_CONCURRENCY,  # ë™ì‹œ ì²˜ë¦¬ ìˆ˜
    tensor_parallel_size=1,
    gpu_memory_utilization=0.9,
    disable_mm_preprocessor_cache=True
)
```

#### 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
**vLLM ì „ìš© ì „ì²˜ë¦¬ í•„ìš”**:
```python
from process.image_process import DeepseekOCRProcessor

processor = DeepseekOCRProcessor()
multi_modal_data = {
    "image": processor.tokenize_with_images(
        images=[image],
        bos=True,
        eos=True,
        cropping=CROP_MODE
    )
}
```

#### 3. ì¶”ë¡  í˜¸ì¶œ
**HF Transformers**:
```python
response = self.model.infer(
    tokenizer=self.tokenizer,
    prompt="<image>\n<|grounding|>...",
    image_file="/tmp/temp.png",
    output_path="/tmp/output",
    base_size=1024,
    image_size=640,
    crop_mode=True,
    save_results=False,
)
```

**vLLM**:
```python
batch_inputs = [
    {
        "prompt": "<image>\n<|grounding|>...",
        "multi_modal_data": {"image": processed_image_data}
    }
    for processed_image_data in preprocessed_images
]

outputs = llm.generate(batch_inputs, sampling_params)
for output in outputs:
    response = output.outputs[0].text
```

#### 4. ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„°
```python
from vllm import SamplingParams
from process.ngram_norepeat import NoRepeatNGramLogitsProcessor

logits_processors = [
    NoRepeatNGramLogitsProcessor(
        ngram_size=20,
        window_size=50,
        whitelist_token_ids={128821, 128822}  # <td>,</td>
    )
]

sampling_params = SamplingParams(
    temperature=0.0,  # Greedy decoding
    max_tokens=8192,
    logits_processors=logits_processors,
    skip_special_tokens=False,
    include_stop_str_in_output=True,
)
```

---

## ğŸ“ íŒŒì¼ êµ¬ì¡° ë³€ê²½

### ì‹ ê·œ íŒŒì¼
```
src/deepseek_ocr/
â”œâ”€â”€ engine/
â”‚   â”œâ”€â”€ deepseek_vllm_engine.py   # ğŸ†• vLLM ì—”ì§„ (ê¸°ì¡´ deepseek_engine.py ëŒ€ì²´)
â”‚   â”œâ”€â”€ image_processor.py        # ğŸ†• ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ê³µì‹ ì½”ë“œ ì´ì‹)
â”‚   â”œâ”€â”€ logits_processor.py       # ğŸ†• NoRepeatNGramLogitsProcessor
â”‚   â””â”€â”€ prompts.py                # âœ… ê¸°ì¡´ ìœ ì§€ (ê³µì‹ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ pdf_parser.py             # âœ… ê¸°ì¡´ ìœ ì§€
â”‚   â”œâ”€â”€ markdown_parser.py        # ğŸ†• ì‹ ê·œ (markdown grounding íŒŒì‹±)
â”‚   â”œâ”€â”€ structure_analyzer_vllm.py # ğŸ†• vLLM ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
â”‚   â”œâ”€â”€ element_analyzer_vllm.py   # ğŸ†• vLLM ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
â”‚   â””â”€â”€ text_enricher.py          # âœ… ê¸°ì¡´ ìœ ì§€
â”‚
â””â”€â”€ core/
    â”œâ”€â”€ config.py                  # âœ… ìˆ˜ì • (vLLM ì„¤ì • ì¶”ê°€)
    â””â”€â”€ types.py                   # âœ… ê¸°ì¡´ ìœ ì§€
```

### ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸
```python
# src/deepseek_ocr/core/config.py

@dataclass
class Config:
    # vLLM ì „ìš© ì„¤ì •
    engine_type: str = "vllm"  # "vllm" or "hf"

    # vLLM íŒŒë¼ë¯¸í„°
    max_num_seqs: int = 100  # ë™ì‹œ ì²˜ë¦¬ ì‹œí€€ìŠ¤ ìˆ˜ (RTX 4090: 100, RTX 4060: 10)
    gpu_memory_utilization: float = 0.9  # GPU ë©”ëª¨ë¦¬ í™œìš©ë¥ 
    block_size: int = 256
    tensor_parallel_size: int = 1

    # ì „ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
    num_workers: int = 64  # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë³‘ë ¬ ì›Œì»¤

    # ê¸°ì¡´ ì„¤ì • ìœ ì§€
    model_name: str = "deepseek-ai/DeepSeek-OCR"
    device: str = "cuda"
    dtype: str = "bfloat16"  # RTX 4090
    base_size: int = 1024
    image_size: int = 640
    crop_mode: bool = True
```

---

## ğŸ”§ êµ¬í˜„ ë‹¨ê³„

### Phase 1: í•µì‹¬ ì¸í”„ë¼ (vLLM ì—”ì§„)
**ëª©í‘œ**: vLLM ê¸°ë°˜ ì¶”ë¡  ì—”ì§„ êµ¬í˜„

**ì‘ì—…**:
1. âœ… `src/deepseek_ocr/engine/image_processor.py` ìƒì„±
   - ê³µì‹ `process/image_process.py` ì½”ë“œ ì´ì‹
   - `DeepseekOCRProcessor` í´ë˜ìŠ¤ êµ¬í˜„

2. âœ… `src/deepseek_ocr/engine/logits_processor.py` ìƒì„±
   - ê³µì‹ `process/ngram_norepeat.py` ì½”ë“œ ì´ì‹
   - `NoRepeatNGramLogitsProcessor` êµ¬í˜„

3. âœ… `src/deepseek_ocr/engine/deepseek_vllm_engine.py` ìƒì„±
   - `DeepSeekVLLMEngine` í´ë˜ìŠ¤ êµ¬í˜„
   - ëª¨ë¸ ì´ˆê¸°í™” (LLM)
   - ë°°ì¹˜ ì¶”ë¡  ë©”ì„œë“œ
   - ë©”ëª¨ë¦¬ ê´€ë¦¬

**ê²€ì¦**:
```python
# ë‹¨ì¼ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸
engine = DeepSeekVLLMEngine(config)
result = engine.infer(image, prompt)
print(result)
```

### Phase 2: ë°°ì¹˜ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
**ëª©í‘œ**: 2-Pass íŒŒì´í”„ë¼ì¸ì˜ vLLM ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

**ì‘ì—…**:
1. âœ… `src/deepseek_ocr/pipeline/structure_analyzer_vllm.py`
   - Pass 1 ë°°ì¹˜ ì²˜ë¦¬ (ì „ì²´ í˜ì´ì§€ ë™ì‹œ ì²˜ë¦¬)
   - ë³‘ë ¬ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ThreadPoolExecutor)
   - Markdown íŒŒì‹±

2. âœ… `src/deepseek_ocr/pipeline/element_analyzer_vllm.py`
   - Pass 2 ë°°ì¹˜ ì²˜ë¦¬ (ì „ì²´ ìš”ì†Œ ë™ì‹œ ì²˜ë¦¬)
   - ìš”ì†Œë³„ í¬ë¡­ + ì „ì²˜ë¦¬ ë³‘ë ¬í™”
   - ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ ìµœì í™”

**ê²€ì¦**:
```python
# 19 í˜ì´ì§€ PDF í…ŒìŠ¤íŠ¸
analyzer = PageStructureAnalyzerVLLM(engine)
structures = analyzer.analyze_batch(page_images)  # 19 í˜ì´ì§€ ë°°ì¹˜ ì²˜ë¦¬
```

### Phase 3: Markdown Parser (ê³µì‹ ë°©ì‹)
**ëª©í‘œ**: `<|ref|>...<|/ref|><|det|>...<|/det|>` íŒŒì‹±

**ì‘ì—…**:
1. âœ… `src/deepseek_ocr/pipeline/markdown_parser.py` ìƒì„±
   - ì •ê·œì‹ ê¸°ë°˜ ref/det ì¶”ì¶œ (ê³µì‹ ì½”ë“œ ì°¸ì¡°)
   - ì¢Œí‘œ ì •ê·œí™” (0-999 â†’ 0-1)
   - 7-Category ë§¤í•‘

**ê²€ì¦**:
```python
# ê³µì‹ ì˜ˆì œ ì¶œë ¥ íŒŒì‹±
markdown = "<|ref|>table<|/ref|><|det|>[100,200,800,600]<|/det|>\n| A | B |\n"
elements = MarkdownParser().parse(markdown)
```

### Phase 4: ì„¤ì • ë° í†µí•©
**ëª©í‘œ**: ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© ë° ì„¤ì • ì—…ë°ì´íŠ¸

**ì‘ì—…**:
1. âœ… `src/deepseek_ocr/core/config.py` ì—…ë°ì´íŠ¸
   - vLLM ì „ìš© ì„¤ì • ì¶”ê°€
   - RTX 4090 / RTX 4060 í”„ë¦¬ì…‹

2. âœ… `src/deepseek_ocr/cli/main.py` ì—…ë°ì´íŠ¸
   - vLLM ì—”ì§„ ì‚¬ìš©
   - ì§„í–‰ ìƒí™© í‘œì‹œ (tqdm)

3. âœ… `runpod/process.py` ì—…ë°ì´íŠ¸
   - vLLM ì—”ì§„ìœ¼ë¡œ ì „í™˜

**ê²€ì¦**:
```bash
python runpod/process.py --input pdfs/ --output outputs/ --preset rtx4090
```

### Phase 5: ì˜ì¡´ì„± ë° í™˜ê²½ ì„¤ì •
**ëª©í‘œ**: vLLM ì˜ì¡´ì„± ì¶”ê°€ ë° í™˜ê²½ êµ¬ì„±

**ì‘ì—…**:
1. âœ… `requirements.txt` ì—…ë°ì´íŠ¸
   ```
   vllm>=0.6.0
   # ê¸°ì¡´ transformersëŠ” ìœ ì§€ (vLLMì´ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©)
   ```

2. âœ… `runpod/setup.sh` ì—…ë°ì´íŠ¸
   - vLLM ì„¤ì¹˜
   - CUDA í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

**ê²€ì¦**:
```bash
python -c "import vllm; print(vllm.__version__)"
```

---

## ğŸ¯ ì„±ëŠ¥ ìµœì í™” ì „ëµ

### 1. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
```python
# Pass 1: ì „ì²´ í˜ì´ì§€ ë°°ì¹˜ ì²˜ë¦¬
def analyze_batch(self, page_images: List[Image.Image]) -> List[PageStructure]:
    # 1. ë³‘ë ¬ ì „ì²˜ë¦¬
    with ThreadPoolExecutor(max_workers=64) as executor:
        batch_inputs = list(executor.map(self._preprocess_image, page_images))

    # 2. vLLM ë°°ì¹˜ ì¶”ë¡  (1íšŒ í˜¸ì¶œë¡œ ì „ì²´ ì²˜ë¦¬)
    outputs = self.engine.llm.generate(batch_inputs, sampling_params)

    # 3. ë³‘ë ¬ íŒŒì‹±
    with ThreadPoolExecutor(max_workers=32) as executor:
        structures = list(executor.map(self._parse_output, outputs, page_images))

    return structures
```

### 2. ë©”ëª¨ë¦¬ ìµœì í™”
- **PagedAttention**: vLLMì˜ í•µì‹¬ ë©”ëª¨ë¦¬ ìµœì í™”
- **ë™ì  ë°°ì¹˜**: `max_num_seqs`ë¡œ ë©”ëª¨ë¦¬ ì••ë ¥ ì¡°ì ˆ
- **GPU ë©”ëª¨ë¦¬ í™œìš©ë¥ **: RTX 4090 0.9, RTX 4060 0.75

### 3. GPU ì„¤ì •
```python
# RTX 4090 (24GB)
max_num_seqs = 100  # ë†’ì€ ë³‘ë ¬ì„±
gpu_memory_utilization = 0.9

# RTX 4060 (8GB)
max_num_seqs = 10   # ì œí•œëœ ë³‘ë ¬ì„±
gpu_memory_utilization = 0.75
```

---

## âœ… ì„±ê³µ ê¸°ì¤€

### 1. ì„±ëŠ¥ ëª©í‘œ
- **ì²˜ë¦¬ ì†ë„**: 19 í˜ì´ì§€ PDF < 2ë¶„ (RTX 4090)
- **ë©”ëª¨ë¦¬ ì•ˆì •ì„±**: OOM ì—†ì´ ì™„ë£Œ
- **ì²˜ë¦¬ëŸ‰**: HF Transformers ëŒ€ë¹„ 3-5ë°° í–¥ìƒ

### 2. ê¸°ëŠ¥ ê²€ì¦
- âœ… Pass 1: ë°°ì¹˜ êµ¬ì¡° ë¶„ì„ (19 í˜ì´ì§€ ë™ì‹œ)
- âœ… Pass 2: ë°°ì¹˜ ìš”ì†Œ ë¶„ì„ (N ìš”ì†Œ ë™ì‹œ)
- âœ… Markdown íŒŒì‹± ì •í™•ë„
- âœ… 7-Category ë¶„ë¥˜
- âœ… í‚¤ì›Œë“œ/ìš”ì•½ ìƒì„±

### 3. í’ˆì§ˆ ê²€ì¦
- âœ… ê³µì‹ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
- âœ… `<|ref|>...<|/ref|>` íŒŒì‹± ì •í™•ë„
- âœ… ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
- âœ… DocJSON ì¶œë ¥ ì™„ì„±ë„

---

## ğŸš€ RunPod ë°°í¬ ê³„íš

### 1. í™˜ê²½ ì„¤ì •
```bash
# vLLM ì„¤ì¹˜
pip install vllm>=0.6.0

# CUDA í™˜ê²½ ë³€ìˆ˜
export VLLM_USE_V1=0
export CUDA_VISIBLE_DEVICES=0
```

### 2. í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
```bash
# 1ë‹¨ê³„: ë‹¨ì¼ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸
python test_vllm_engine.py

# 2ë‹¨ê³„: 3 í˜ì´ì§€ PDF í…ŒìŠ¤íŠ¸
python runpod/process.py --input pdfs/test_3pages.pdf --output outputs/

# 3ë‹¨ê³„: ì „ì²´ 19 í˜ì´ì§€ PDF í…ŒìŠ¤íŠ¸
python runpod/process.py --input pdfs/ --output outputs/ --preset rtx4090
```

### 3. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```bash
# GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi

# ì²˜ë¦¬ ì†ë„ ì¸¡ì •
time python runpod/process.py --input pdfs/ --output outputs/
```

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

1. âœ… Phase 1: vLLM ì—”ì§„ êµ¬í˜„
   - image_processor.py
   - logits_processor.py
   - deepseek_vllm_engine.py

2. âœ… Phase 2: ë°°ì¹˜ íŒŒì´í”„ë¼ì¸
   - structure_analyzer_vllm.py
   - element_analyzer_vllm.py

3. âœ… Phase 3: Markdown íŒŒì„œ
   - markdown_parser.py

4. âœ… Phase 4: ì„¤ì • ë° í†µí•©
   - config.py ì—…ë°ì´íŠ¸
   - main.py ì—…ë°ì´íŠ¸

5. âœ… Phase 5: ì˜ì¡´ì„±
   - requirements.txt
   - setup.sh

6. âœ… í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
7. âœ… RunPod ë°°í¬

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [vLLM ê³µì‹ ë¬¸ì„œ](https://docs.vllm.ai/)
- [DeepSeek-OCR vLLM ì˜ˆì œ](../models/DeepSeek-OCR/DeepSeek-OCR-master/DeepSeek-OCR-vllm/)
- [ì´ì „ HF Transformers ì „ëµ](./IMPLEMENTATION_STRATEGY_2025-10-28.md)
