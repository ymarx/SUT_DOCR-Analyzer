# DeepSeek-OCR êµ¬í˜„ ì „ëµ ë¬¸ì„œ
**ì‘ì„±ì¼**: 2025-10-28
**ëª©ì **: ê³µì‹ API í˜¸í™˜ + í”„ë¡œì íŠ¸ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ 2-Pass Hybrid ë°©ì‹ êµ¬í˜„

---

## ğŸ¯ í”„ë¡œì íŠ¸ í•µì‹¬ ëª©í‘œ

### 1. ì˜ë¯¸ ê²€ìƒ‰ (Vector Search) ìµœì í™”
**ëª©ì **: ë²¡í„° DBì—ì„œ "ì˜ë¯¸ ê²€ìƒ‰"ì„ í–ˆì„ ë•Œ, ë„í‘œ/ê·¸ë˜í”„ì˜ ìì—°ì–´ ìš”ì•½ì„ ì°¸ì¡°í•˜ê³  ì›ë³¸ ìš”ì†Œë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë„ë¡ í•¨

**ìš”êµ¬ì‚¬í•­**:
- âœ… ê·¸ë˜í”„/ë„í‘œì˜ **ìì—°ì–´ ìš”ì•½** ìƒì„±
- âœ… **í‚¤ì›Œë“œ ì¶”ì¶œ** (ë²¡í„° ì„ë² ë”©ìš©)
- âœ… ì›ë³¸ ì´ë¯¸ì§€ **ì°¸ì¡° ë§í¬** ìœ ì§€
- âœ… ì£¼ë³€ ë§¥ë½ ì •ë³´ í¬í•¨

**ì˜ˆì‹œ**:
```json
{
  "element_id": "page_3_graph_2",
  "element_type": "graph",
  "í•­ëª©": ["ì›ì „ ê°€ë™ë¥  ì¶”ì´", "line_chart", "2024ë…„ 1ë¶„ê¸°"],
  "í‚¤ì›Œë“œ": ["ì›ì „", "ê°€ë™ë¥ ", "1ë¶„ê¸°", "2024", "ì¶”ì´", "ì„±ëŠ¥", "ì•ˆì •ì "],
  "ìì—°ì–´ìš”ì•½": "2024ë…„ 1ë¶„ê¸° ì›ì „ ê°€ë™ë¥  ì¶”ì´ ê·¸ë˜í”„. 1í˜¸ê¸° 98.5%, 2í˜¸ê¸° 97.2% ê¸°ë¡í•˜ë©° ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ìš´ì „ ì„±ëŠ¥ ìœ ì§€.",
  "image_path": "outputs/images/page_3_graph_2.png",
  "bbox": [550, 350, 900, 700]
}
```

### 2. 7ê°œ ìš”ì†Œì˜ ë‚´ì¬ì  ë‚´ìš© + ì£¼ë³€ ì •ë³´ í™œìš©
**ëª©ì **: ê° ìš”ì†Œ(table, graph, diagram ë“±)ì˜ ìì²´ ë‚´ìš©ë¿ ì•„ë‹ˆë¼ **ì£¼ë³€ í…ìŠ¤íŠ¸**ë„ í™œìš©í•˜ì—¬ ì˜ë¯¸ ìˆëŠ” í‚¤ì›Œë“œ/ìš”ì•½ ìƒì„±

**7-Category Classification**:
1. `text_header`: ë¬¸ì„œ ì œëª©, í° ì œëª©
2. `text_section`: ë„˜ë²„ë§ëœ ì„¹ì…˜ ì œëª© (1., 1.1., 1.1.1.)
3. `text_paragraph`: ì¼ë°˜ ë‹¨ë½ í…ìŠ¤íŠ¸
4. `table`: í‘œ
5. `graph`: ê·¸ë˜í”„, ì°¨íŠ¸
6. `diagram`: ìˆœì„œë„, ê³µì •ë„
7. `complex_image`: ë³µì¡í•œ ì´ë¯¸ì§€, ì‚¬ì§„

**ì£¼ë³€ ì •ë³´ í™œìš© ë°©ì‹**:
```python
# Example: ê·¸ë˜í”„ ë¶„ì„ ì‹œ
context = extract_surrounding_text(
    target_element=graph_element,
    all_elements=page_elements,
    radius=0.2  # í˜ì´ì§€ ë†’ì´ì˜ 20% ë²”ìœ„ ë‚´
)

prompt = f"""<image>
<|grounding|>Analyze this graph.

Context from surrounding text:
{context}  # â† ì£¼ë³€ ë‹¨ë½ í…ìŠ¤íŠ¸ í¬í•¨

Extract:
1. [í•­ëª©] Graph title, type, axes, legend, trends
2. [í‚¤ì›Œë“œ] 5-10 keywords (including from context)
3. [ìì—°ì–´ ìš”ì•½] 2-3 sentence summary
"""
```

### 3. ê³µì‹ ë¬¸ì„œ ë°©ì‹ ì¤€ìˆ˜
**ì œì•½**: JSON ì§ì ‘ ì¶œë ¥, ë³µì¡í•œ í”„ë¡¬í”„íŠ¸ëŠ” ì˜ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ

**í•´ê²°ì±…**:
- âœ… **Pass 1**: ê³µì‹ `<|grounding|>` markdown ì‚¬ìš©
- âœ… **Pass 2**: Element-specific í”„ë¡¬í”„íŠ¸ (ê°„ê²°í•˜ê²Œ)
- âŒ JSON schema ê°•ìš”í•˜ì§€ ì•ŠìŒ
- âŒ ê³¼ë„í•˜ê²Œ ë³µì¡í•œ ì§€ì‹œì‚¬í•­ ì§€ì–‘

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

### ì „ì²´ êµ¬ì¡°
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PDF Document                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   PDFParser            â”‚
         â”‚   - pdf2image          â”‚
         â”‚   - DPI: 200           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Pass 1: Structure     â”‚
         â”‚  Detection             â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚ Official Prompt  â”‚  â”‚
         â”‚  â”‚ <|grounding|>    â”‚  â”‚
         â”‚  â”‚ Markdown output  â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚ MarkdownParser   â”‚  â”‚
         â”‚  â”‚ Parse refs/dets  â”‚  â”‚
         â”‚  â”‚ Extract elements â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼ List[ElementDetection]
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Pass 2: Element       â”‚
         â”‚  Analysis              â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚ For each element â”‚  â”‚
         â”‚  â”‚ - Crop image     â”‚  â”‚
         â”‚  â”‚ - Extract contextâ”‚  â”‚
         â”‚  â”‚ - Detailed promptâ”‚  â”‚
         â”‚  â”‚ - Parse response â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼ List[ElementAnalysis]
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  DocJSON Generation    â”‚
         â”‚  - Combine structure   â”‚
         â”‚  â”‚  + analysis          â”‚
         â”‚  - Save images         â”‚
         â”‚  - Build DocJSON       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Output:               â”‚
         â”‚  - docjson.json        â”‚
         â”‚  - images/*.png        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2-Pass íŒŒì´í”„ë¼ì¸ ìƒì„¸

#### **Pass 1: Page Structure Detection**
```python
# Input
page_image: PIL.Image

# Prompt (ê³µì‹ ë°©ì‹)
prompt = "<image>\n<|grounding|>Convert the document to markdown."

# Output (example)
"""
<|ref|>title<|/ref|><|det|>[100,50,900,120]<|/det|>
# ë…¸ì—´ê´€ë¦¬ ê¸°ì¤€

<|ref|>text_paragraph<|/ref|><|det|>[100,150,900,300]<|/det|>
ë³¸ ê¸°ì¤€ì€ ë…¸ì € ëƒ‰ì…ì‚¬ê³  ì‹œ ë³µêµ¬ ì ˆì°¨ë¥¼ ì •ì˜í•œë‹¤.

<|ref|>table<|/ref|><|det|>[100,350,500,700]<|/det|>
| í•­ëª© | ë‚´ìš© |
|------|------|
| ... | ... |

<|ref|>figure<|/ref|><|det|>[550,350,900,700]<|/det|>
[Graph showing performance trends...]
"""

# Parsing
elements = MarkdownGroundingParser().parse(markdown_output)
# â†’ List[ElementDetection]
#   - element_id: "e1", "e2", ...
#   - element_type: TEXT_HEADER, TEXT_PARAGRAPH, TABLE, GRAPH, ...
#   - bbox: BoundingBox(x1, y1, x2, y2)
#   - text_preview: "first 50 chars..."
```

#### **Pass 2: Element-Specific Analysis**
```python
# For each element detected in Pass 1
for element in elements:
    # 1. Crop element from page
    cropped_image = crop_element(page_image, element.bbox)

    # 2. Extract surrounding context
    context = extract_surrounding_context(
        element=element,
        all_elements=elements,
        markdown_text=pass1_markdown_output
    )

    # 3. Generate element-specific prompt
    prompt = get_element_prompt(element.element_type, context)

    # Example for GRAPH:
    """
    <image>
    <|grounding|>Analyze this graph element in detail.

    Context from surrounding text:
    ë³¸ ê¸°ì¤€ì€ ë…¸ì € ëƒ‰ì…ì‚¬ê³  ì‹œ ë³µêµ¬ ì ˆì°¨ë¥¼ ì •ì˜í•œë‹¤.

    Extract the following:
    1. [í•­ëª©] Graph components (title, type, axes, legend, trends)
    2. [í‚¤ì›Œë“œ] 5-10 important keywords
    3. [ìì—°ì–´ ìš”ì•½] 2-3 sentence summary
    """

    # 4. Analyze
    response = engine.infer(cropped_image, prompt)

    # 5. Parse response (flexible)
    analysis = parse_element_response(response, element.element_type)
    # â†’ ElementAnalysis
    #   - í•­ëª©: List[str]
    #   - í‚¤ì›Œë“œ: List[str]
    #   - ìì—°ì–´ìš”ì•½: str
```

---

## ğŸ“ íŒŒì¼ êµ¬ì¡° ë° ì—­í• 

```
src/deepseek_ocr/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py          # Config ì„¤ì •
â”‚   â”œâ”€â”€ types.py           # Data classes (ElementDetection, ElementAnalysis, etc.)
â”‚   â””â”€â”€ utils.py           # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚
â”œâ”€â”€ engine/
â”‚   â”œâ”€â”€ deepseek_engine.py      # âœ… ìˆ˜ì •: output_path ì¶”ê°€
â”‚   â””â”€â”€ prompts.py              # âœ… ìˆ˜ì •: ê³µì‹ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ pdf_parser.py           # PDF â†’ Images
â”‚   â”œâ”€â”€ markdown_parser.py      # ğŸ†• ì‹ ê·œ: Markdown grounding â†’ Elements
â”‚   â”œâ”€â”€ structure_analyzer.py   # âœ… ìˆ˜ì •: Pass 1 with markdown parser
â”‚   â”œâ”€â”€ element_analyzer.py     # âœ… ìˆ˜ì •: Pass 2 with context extraction
â”‚   â””â”€â”€ text_enricher.py        # DocJSON ìƒì„±
â”‚
â””â”€â”€ cli/
    â””â”€â”€ main.py            # CLI entrypoint
```

---

## ğŸ”§ êµ¬í˜„ ë‹¨ê³„

### Phase 1: Core Infrastructure (output_path fix)
**íŒŒì¼**: `deepseek_engine.py`

**ë³€ê²½ì‚¬í•­**:
```python
response = self.model.infer(
    tokenizer=self.tokenizer,
    prompt=prompt,
    image_file=temp_path,
    output_path=temp_output_dir,  # âœ… REQUIRED
    base_size=self.config.base_size,
    image_size=self.config.image_size,
    crop_mode=self.config.crop_mode,
    save_results=False,
    test_compress=False,
)
```

**ì´ìœ **:
- `modeling_deepseekocr.py:706` calls `os.makedirs(output_path, exist_ok=True)`
- Empty string causes `[Errno 2] No such file or directory: ''`

---

### Phase 2: Official Prompt Integration
**íŒŒì¼**: `prompts.py`

**ë³€ê²½ì‚¬í•­**:
```python
# Pass 1: Official grounding prompt
STRUCTURE_ANALYSIS_PROMPT = "<image>\n<|grounding|>Convert the document to markdown."

# Pass 2: Element-specific prompts (ê¸°ì¡´ ìœ ì§€, ë‹¨ìˆœí™”)
GRAPH_ANALYSIS_PROMPT = """<image>
<|grounding|>Analyze this graph element in detail.

Context from surrounding text:
{context}

Extract the following:
1. [í•­ëª©] Graph components: title, type, axes, legend, trends
2. [í‚¤ì›Œë“œ] 5-10 important keywords
3. [ìì—°ì–´ ìš”ì•½] 2-3 sentence summary describing what the graph shows
"""
```

**ë³€ê²½ í¬ì¸íŠ¸**:
- âŒ JSON schema ì œê±°
- âŒ ë³µì¡í•œ output format ì§€ì‹œ ì œê±°
- âœ… ê°„ê²°í•˜ê³  ëª…í™•í•œ ì§€ì‹œ
- âœ… `<|grounding|>` í† í° í™œìš©

---

### Phase 3: Markdown Parser (NEW)
**íŒŒì¼**: `markdown_parser.py` (ì‹ ê·œ)

**ê¸°ëŠ¥**:
1. Parse `<|ref|>...<|/ref|><|det|>...<|/det|>` patterns
2. Extract bounding boxes (normalized 0-999 â†’ 0-1)
3. Map official labels to 7-category types
4. Extract markdown content between refs

**í´ë˜ìŠ¤**:
```python
class MarkdownGroundingParser:
    def parse(self, markdown_text: str) -> List[ElementDetection]:
        """Parse grounding markdown into structured elements."""

    def _map_label(self, label: str) -> ElementType:
        """Map official label to 7-category."""

    def _extract_content(self, text: str, idx: int) -> str:
        """Extract markdown content for element."""
```

---

### Phase 4: Structure Analyzer Update
**íŒŒì¼**: `structure_analyzer.py`

**ë³€ê²½ì‚¬í•­**:
```python
from .markdown_parser import MarkdownGroundingParser

class PageStructureAnalyzer:
    def __init__(self, engine: DeepSeekEngine):
        self.engine = engine
        self.parser = MarkdownGroundingParser()  # âœ… ì¶”ê°€

    def analyze(self, page_image: Image.Image, page_num: int) -> PageStructure:
        # Use official prompt
        prompt = "<image>\n<|grounding|>Convert the document to markdown."

        # Get markdown with grounding
        markdown_output = self.engine.infer(page_image, prompt)

        # Parse into elements
        elements = self.parser.parse(markdown_output)

        return PageStructure(
            page_number=page_num,
            elements=elements,
            raw_markdown=markdown_output,  # âœ… ì›ë³¸ ì €ì¥
        )
```

---

### Phase 5: Element Analyzer Update
**íŒŒì¼**: `element_analyzer.py`

**ë³€ê²½ì‚¬í•­**:
```python
def analyze(
    self,
    element: ElementDetection,
    page_image: Image.Image,
    all_elements: List[ElementDetection],
    markdown_text: str  # âœ… Pass 1 markdown
) -> ElementAnalysis:
    # 1. Crop element
    cropped_image = crop_element(page_image, element.bbox)

    # 2. Extract context
    context = self._extract_context(
        element, all_elements, markdown_text  # âœ… ì£¼ë³€ ì •ë³´ í™œìš©
    )

    # 3. Element-specific prompt
    prompt = get_element_prompt(element.element_type, context)

    # 4. Analyze
    response = self.engine.infer(cropped_image, prompt)

    # 5. Parse (flexible, no strict JSON)
    analysis = self._parse_response(response)

    return ElementAnalysis(
        element_id=element.element_id,
        í•­ëª©=analysis.get("items", []),
        í‚¤ì›Œë“œ=analysis.get("keywords", []),
        ìì—°ì–´ìš”ì•½=analysis.get("summary", ""),
    )

def _extract_context(self, element, all_elements, markdown_text) -> str:
    """Extract surrounding text context from nearby elements."""
    # Find spatially nearby elements
    # Extract their markdown content
    # Prioritize text_paragraph, text_section
    # Return concatenated context (max 500 chars)
```

---

## âœ… ì„±ê³µ ê¸°ì¤€

### 1. ê¸°ëŠ¥ ê²€ì¦
- âœ… PDF íŒŒì‹± ì„±ê³µ (19 í˜ì´ì§€ ì¸ì‹)
- âœ… Pass 1: Element detection with bbox
- âœ… Pass 2: Detailed analysis with context
- âœ… DocJSON ìƒì„± ì™„ë£Œ

### 2. í’ˆì§ˆ ê²€ì¦
- âœ… ê·¸ë˜í”„/ë„í‘œì— ëŒ€í•œ ìì—°ì–´ ìš”ì•½ ìƒì„±
- âœ… í‚¤ì›Œë“œ 5-10ê°œ ì¶”ì¶œ
- âœ… ì£¼ë³€ ë§¥ë½ ì •ë³´ í¬í•¨
- âœ… 7-category ë¶„ë¥˜ ì •í™•ë„

### 3. ì„±ëŠ¥ ê²€ì¦
- âœ… RTX 4090: 1 PDF (19 í˜ì´ì§€) < 5ë¶„
- âœ… ë©”ëª¨ë¦¬ ì•ˆì •ì„± (no OOM)
- âœ… ì¶œë ¥ íŒŒì¼ êµ¬ì¡° ì™„ì„±

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

1. âœ… `deepseek_engine.py` ìˆ˜ì • (output_path)
2. âœ… `prompts.py` ìˆ˜ì • (ê³µì‹ í”„ë¡¬í”„íŠ¸)
3. ğŸ†• `markdown_parser.py` êµ¬í˜„
4. âœ… `structure_analyzer.py` ìˆ˜ì •
5. âœ… `element_analyzer.py` ìˆ˜ì •
6. âœ… í†µí•© í…ŒìŠ¤íŠ¸
7. âœ… RunPod ë°°í¬ ë° ê²€ì¦

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- [DeepSeek-OCR ë…¼ë¬¸](../models/DeepSeek-OCR/DeepSeek_OCR_paper.pdf)
- [ê³µì‹ GitHub](https://github.com/deepseek-ai/DeepSeek-OCR)
- [í”„ë¡œì íŠ¸ ì „ì²´ ì„¤ê³„](./3_ì „ì²´_ì„¤ê³„_ë°_ì „ëµ.md)
- [ê³µì‹ ì˜ˆì œ ì½”ë“œ](../models/DeepSeek-OCR/DeepSeek-OCR-master/DeepSeek-OCR-hf/run_dpsk_ocr.py)
